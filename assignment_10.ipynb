{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e502fdc2-b0d1-44b1-b582-0ce249888cc9",
   "metadata": {},
   "source": [
    "## Q1.  The feature extraction network comprises loads of convolutional and pooling layer pairs. Convolutional layer consists of a collection of digital filters to perform the convolution operation on the input data. The pooling layer is used as a dimensionality reduction layer and decides the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2a0b49-1494-45f0-b5c5-f0c2e49ee99e",
   "metadata": {},
   "source": [
    "## Q2.  Backpropagation is a process involved in training a neural network. It involves taking the error rate of a forward propagation and feeding this loss backward through the neural network layers to fine-tune the weights. Backpropagation is the essence of neural net training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87211d64-643f-4c84-b3b0-9f9cb921cfe8",
   "metadata": {},
   "source": [
    "## Q3.  Advantages of using transfer learning in machine learning\n",
    "### It saves time and resources. Most machine learning problems involve training a large amount of data. This type of labeled training data takes more time. However, in transfer learning most models are pre-trained, which reduces the size of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27026e7a-a4bc-4bdd-82ef-d72e9133b036",
   "metadata": {},
   "source": [
    "## Q4.  Data augmentation is the addition of new data artificially derived from existing training data. Techniques include resizing, flipping, rotating, cropping, padding, etc. It helps to address issues like overfitting and data scarcity, and it makes the model robust with better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94bb0f-6b2c-43a3-9522-48fac3cedefb",
   "metadata": {},
   "source": [
    "## Q5.  Therefore, the model first uses 1 CNN to obtain region proposals, then follows exactly the same logic with Fast RCNN to detect objects, so it uses these proposals to extract features with CNN, then classify with Fully Connected Layers and improve the ROIs using bounding box regressor\n",
    "### If the task involves object detection or segmentation, then architectures like YOLO, RCNN, or Mask R-CNN might be suitable. If the task involves processing sequential data such as speech or text, then architectures such as Convolutional LSTM or Time Distributed CNN might be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb325f0-6591-40ce-8f83-c81bd3d6b2e0",
   "metadata": {},
   "source": [
    "## Q6.  How do convolutional neural networks work? A CNN can have multiple layers, each of which learns to detect the different features of an input image. A filter or kernel is applied to each image to produce an output that gets progressively better and more detailed after each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7176e86-2745-4de5-a0a2-78cea044f43b",
   "metadata": {},
   "source": [
    "## Q7.  Image segmentation is a crucial task in computer vision, where the goal is to divide an image into different meaningful and distinguishable regions or objects. It is a fundamental task in various applications such as object recognition, tracking, and detection, medical imaging, and robotics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875c2a9-6841-45cb-9a9c-57f55536b9c2",
   "metadata": {},
   "source": [
    "## Q8.  Overfitting, exploding gradient, and class imbalance are the major challenges while training the model using CNN. These issues can diminish the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22fda10-bf7c-4724-a93e-a1b7ef5af961",
   "metadata": {},
   "source": [
    "## Q9.  An embedding is a relatively low-dimensional space into which you can translate high-dimensional vectors. Embeddings make it easier to do machine learning on large inputs like sparse vectors representing words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac05461-85c3-41a6-a33c-18bf235fea41",
   "metadata": {},
   "source": [
    "## Q10.  With model distillation, a separate inference-optimized model is trained using the training-optimized model, in a process known as distillation, where knowledge transfer happens. If done correctly, model distillation allows the inference-optimized model to keep almost all the quality of the training-optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06a094-28ea-4fca-880b-ce2268e276ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
