{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28025c73-e25b-4793-b209-b8c31d4ab164",
   "metadata": {},
   "source": [
    "## Q1.  Linear regression is used to predict the continuous dependent variable using a given set of independent variables. Logistic Regression is used to predict the categorical dependent variable using a given set of independent variables. Linear Regression is used for solving Regression problem.\n",
    "### Logistic Regression is used when the dependent variable(target) is categorical. For example, To predict whether an email is spam (1) or (0) Whether the tumor is malignant (1) or not (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714689ec-f91e-47c7-95a1-9fbce944261a",
   "metadata": {},
   "source": [
    "## Q2.  The cost function used in Logistic Regression is Log Loss\n",
    "### to minimize log_loss, one must be able to calculate (estimate) the probabilities of belonging to classes. This explains why the entropy criterion of splitting (branching) is used when constructing decision trees in classification problems (as well as random forests and trees in boosting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e415f-61cf-433f-b8b3-6414bd4abc89",
   "metadata": {},
   "source": [
    "## Q3.  “Regularization is any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error.” In other words: regularization can be used to train models that generalize better on unseen data, by preventing the algorithm from overfitting the training dataset.\n",
    "### Regularization is a technique that adds information to a model to prevent the occurrence of overfitting. It is a type of regression that minimizes the coefficient estimates to zero to reduce the capacity (size) of a model. In this context, the reduction of the capacity of a model involves the removal of extra weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa52b9f-c0ff-48c3-bc08-e3fc3c674827",
   "metadata": {},
   "source": [
    "## Q4.  An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate. False Positive Rate.\n",
    "### ROC curves in logistic regression are used for determining the best cutoff value for predicting whether a new observation is a \"failure\" (0) or a \"success\" (1). If you're not familiar with ROC curves, they can take some effort to understand. An example of an ROC curve from logistic regression is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293beed7-46f7-476f-8a06-5782ae8589c3",
   "metadata": {},
   "source": [
    "## Q5.  There are several types of statistical tests that can be used for filter feature selection, including chi-square, ANOVA, and mutual information. These tests measure the degree of association between the features and the target variable, and can help identify the most relevant features for the model.\n",
    "### Feature Selection is the method of reducing the input variable to your model by using only relevant data and getting rid of noise in data. It is the process of automatically choosing relevant features for your machine learning model based on the type of problem you are trying to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eb680f-3e99-4115-b944-5a1b4065940f",
   "metadata": {},
   "source": [
    "## Q6.  In logistic regression, another technique comes handy to work with imbalance distribution. This is to use class-weights in accordance with the class distribution. Class-weights is the extent to which the algorithm is punished for any wrong prediction of that class.\n",
    "### Approach to deal with the imbalanced dataset problem\n",
    "- Choose Proper Evaluation Metric. The accuracy of a classifier is the total number of correct predictions by the classifier divided by the total number of predictions. ...\n",
    "- Resampling (Oversampling and Undersampling) ...\n",
    "- SMOTE. ...\n",
    "- BalancedBaggingClassifier. ...\n",
    "- Threshold moving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d6d19d-dfa2-4225-98aa-39849b8166b7",
   "metadata": {},
   "source": [
    "## Q7.  Disadvantages of logistic regression\n",
    "- Logistic regression fails to predict a continuous outcome. ...\n",
    "- Logistic regression assumes linearity between the predicted (dependent) variable and the predictor (independent) variables. ...\n",
    "- Logistic regression may not be accurate if the sample size is too small.\n",
    "### Strengths: Outputs have a nice probabilistic interpretation, and the algorithm can be regularized to avoid overfitting. Logistic models can be updated easily with new data using stochastic gradient descent. Weaknesses: Logistic regression tends to underperform when there are multiple or non-linear decision boundaries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
