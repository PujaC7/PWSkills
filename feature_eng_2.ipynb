{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec2c892-522b-4abe-8895-02e175d7d1da",
   "metadata": {},
   "source": [
    "## Q1.   In Filter Method, features are selected on the basis of statistics measures. This method does not depend on the learning algorithm and chooses the features as a pre-processing step. The filter method filters out the irrelevant feature and redundant columns from the model by using different metrics through ranking.\n",
    "### Feature Selection is the method of reducing the input variable to your model by using only relevant data and getting rid of noise in data. It is the process of automatically choosing relevant features for your machine learning model based on the type of problem you are trying to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c5ae9e-d1bd-4771-a5e8-eec4b3374bdf",
   "metadata": {},
   "source": [
    "## Q2.  Filter methods measure the relevance of features by their correlation with dependent variable while wrapper methods measure the usefulness of a subset of feature by actually training a model on it. Filter methods are much faster compared to wrapper methods as they do not involve training the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b303ed1-bab6-417a-91f6-d72497c2bd48",
   "metadata": {},
   "source": [
    "## Q3.   Some examples of embedded methods include decision tree-based algorithms (e.g., decision tree, random forest, gradient boosting), and feature selection using regularization models (e.g., LASSO or elastic net)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc68c19-b520-458e-824b-87d1ae170006",
   "metadata": {},
   "source": [
    "## Q4.   The common disadvantage of filter methods is that they ignore the interaction with the classifier and each feature is considered independently thus ignoring feature dependencies In addition, it is not clear how to determine the threshold point for rankings to select only the required features and exclude noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dbc59d-083d-49ea-932e-256491c13713",
   "metadata": {},
   "source": [
    "## Q5.  Filter methods are much faster compared to wrapper methods as they do not involve training the models. On the other hand, wrapper methods are computationally very expensive as well. Filter methods use statistical methods for evaluation of a subset of features while wrapper methods use cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ece74e-48c5-4bf2-b15b-65bf651d58d4",
   "metadata": {},
   "source": [
    "## Q6.  In a telecom company, you are working on a project to develop a predictive model for customer churn. You are unsure of which features to include in the model because the dataset contains several different ones. I choose chi square test for the model using the Filter Method.\n",
    "### Chi-square Test: Chi-square test is a technique to determine the relationship between the categorical variables. The chi-square value is calculated between each feature and the target variable, and the desired number of features with the best chi-square value is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750fc52-ea4a-4ea7-8ef8-648fbd8b2710",
   "metadata": {},
   "source": [
    "## Q7.  You are working on a project to predict the outcome of a soccer match. You have a large dataset with many features, including player statistics and team rankings. I use the Embedded method to select the most relevant features for the model.\n",
    "### Regularization- Regularization adds a penalty term to different parameters of the machine learning model for avoiding overfitting in the model. This penalty term is added to the coefficients; hence it shrinks some coefficients to zero. Those features with zero coefficients can be removed from the dataset. The types of regularization techniques are L1 Regularization (Lasso Regularization) or Elastic Nets (L1 and L2 regularization).\n",
    "### Random Forest Importance - Different tree-based methods of feature selection help us with feature importance to provide a way of selecting features. Here, feature importance specifies which feature has more importance in model building or has a great impact on the target variable. Random Forest is such a tree-based method, which is a type of bagging algorithm that aggregates a different number of decision trees. It automatically ranks the nodes by their performance or decrease in the impurity (Gini impurity) over all the trees. Nodes are arranged as per the impurity values, and thus it allows to pruning of trees below a specific node. The remaining nodes create a subset of the most important features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c3a73-74ee-4742-95e3-b48944f9a759",
   "metadata": {},
   "source": [
    "## Q8.  You are working on a project to predict the price of a house based on its features, such as size, location, and age. You have a limited number of features, and you want to ensure that you select the most important ones for the model. I use the Wrapper method to select the best set of features for the predictor.\n",
    "### Backward elimination - Backward elimination is also an iterative approach, but it is the opposite of forward selection. This technique begins the process by considering all the features and removes the least significant feature. This elimination process continues until removing the features does not improve the performance of the model.\n",
    "### Exhaustive Feature Selection- Exhaustive feature selection is one of the best feature selection methods, which evaluates each feature set as brute-force. It means this method tries & make each possible combination of features and return the best performing feature set.\n",
    "### Recursive Feature Elimination-Recursive feature elimination is a recursive greedy optimization approach, where features are selected by recursively taking a smaller and smaller subset of features. Now, an estimator is trained with each set of features, and the importance of each feature is determined using coef_attribute or through a feature_importances_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8c4f4-e3bd-44e0-9e43-e54437479b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
